<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.0">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2021-09-06T21:48:58-04:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Adam Laiacano</title><subtitle>I'll attempt to infrequently post about ML Systems, Data Engineering, and  other things I come up with from time to time.</subtitle><entry><title type="html">My Life in the Data Mesh</title><link href="http://localhost:4000/2021/09/05/data-mesh.html" rel="alternate" type="text/html" title="My Life in the Data Mesh" /><published>2021-09-05T01:00:00-04:00</published><updated>2021-09-05T01:00:00-04:00</updated><id>http://localhost:4000/2021/09/05/data-mesh</id><content type="html" xml:base="http://localhost:4000/2021/09/05/data-mesh.html">&lt;blockquote class=&quot;twitter-tweet&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;I like the concept of Data Mesh OK, but _love_ the Data Mesh drama on Twitter. üçø&lt;/p&gt;&amp;mdash; Adam Laiacano (@adamlaiacano) &lt;a href=&quot;https://twitter.com/adamlaiacano/status/1426254483764416514?ref_src=twsrc%5Etfw&quot;&gt;August 13, 2021&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async=&quot;&quot; src=&quot;https://platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DATA MESH&lt;/code&gt; has been a &lt;a href=&quot;https://twitter.com/jcristharif/status/1426320304591327234&quot;&gt;very&lt;/a&gt; popular &lt;a href=&quot;https://twitter.com/bernhardsson/status/1400461693197570051&quot;&gt;punching bag&lt;/a&gt; on Twitter lately. The volume of jokes has been matched by a &lt;a href=&quot;https://cnr.sh/essays/what-the-heck-data-mesh&quot;&gt;burst&lt;/a&gt; of &lt;a href=&quot;https://martinfowler.com/articles/data-mesh-principles.html&quot;&gt;blog posts&lt;/a&gt; &lt;a href=&quot;https://datameshlearning.substack.com/p/okay-but-just-wtf-is-a-data-mesh&quot;&gt;earnestly explaining&lt;/a&gt; &lt;a href=&quot;https://towardsdatascience.com/what-is-a-data-mesh-and-how-not-to-mesh-it-up-210710bb41e0&quot;&gt;what a Data Mesh is&lt;/a&gt; followed by more tweets from people saying they still don‚Äôt understand. When I first heard the term and read about it, I recognized it as the framework that I‚Äôve been working in for the last 5 years.&lt;/p&gt;

&lt;p&gt;Inspired by &lt;a href=&quot;https://www.ethanrosenthal.com/2021/02/03/feature-stores-self-service/&quot;&gt;Ethan Rosenthal‚Äôs post about feature stores&lt;/a&gt;, I‚Äôm going to write this from the perspective of someone working at a company with a Data Mesh architecture, rather than continuing to define what it is or how/when/if it‚Äôs a good idea to transition to one.&lt;/p&gt;

&lt;h2 id=&quot;an-appreciation-for-scale&quot;&gt;An appreciation for scale&lt;/h2&gt;

&lt;p&gt;Before joining Spotify in 2016, I was working on Machine Learning at Stripe, where we used &lt;a href=&quot;https://github.com/stripe-archive/timberlake&quot;&gt;Timberlake&lt;/a&gt; to monitor the progress of map/reduce jobs on the Hadoop cluster. There was one Hadoop cluster which was used for all data processing tasks at the time - mostly by the data team, which included the ML group. When I arrived at Spotify I suggested we use it as well since it was so handy at Stripe. Someone from the data infrastructure group quoted this clip from the Timberlake README:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;[Stripe‚Äôs] cluster has 10-40 jobs running simultaneously and about 2,000 jobs running per day. Timberlake‚Äôs performance has not been tested outside these bounds.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;I was told it wouldn‚Äôt work because Spotify, in 2016, was often running 2,000 Hadoop jobs &lt;em&gt;concurrently&lt;/em&gt;. Ignore the number of gigabytes being processed, this is a full two orders of magnitude difference in the number of &lt;em&gt;jobs&lt;/em&gt; being run. And it wasn‚Äôt just one ‚Äúdata team‚Äù who was using the Hadoop cluster - it seemed like there were 100 different teams each with a couple of data engineers, all submitting &lt;a href=&quot;github.com/twitter/scalding&quot;&gt;Scalding&lt;/a&gt; or &lt;a href=&quot;https://crunch.apache.org/&quot;&gt;Crunch&lt;/a&gt; jobs to prepare data for whatever product they were working on. If you find it difficult to imagine having 100x more data pipelines running at your company, mostly by people you‚Äôve never met, it might also be difficult to appreciate the value of a Data Mesh.&lt;/p&gt;

&lt;p&gt;So now let‚Äôs imagine onboarding into such a company.&lt;/p&gt;

&lt;h2 id=&quot;part-1-let-me-see-some-data&quot;&gt;Part 1: Let me see some data&lt;/h2&gt;

&lt;p&gt;You‚Äôre a data-focused engineer (Data Engineer, Data Scientist, ML Engineer) joining The Company. Welcome to the team! What‚Äôs the first thing you ask once you get your laptop set up? &lt;em&gt;Where can I find the data?&lt;/em&gt; ‚Äú&lt;a href=&quot;https://www.backstage.io&quot;&gt;Backstage&lt;/a&gt;,‚Äù says your teammate. So you fire up &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;thecompany.net/backstage&lt;/code&gt; and see that it‚Äôs some sort of developer portal with information about ‚ÄúDataSets‚Äù (one word, camel case) as well as all kinds of other things about microservices and an org chart. You browse a few ‚ÄúRecommended‚Äù DataSets and one catches your eye - &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;artist-meta.DominantGenres&lt;/code&gt;. You click on the page and see all kinds of links and information about the DataSet.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Owner - A punny team name with a link to a Slack channel and the handle for their PM.&lt;/li&gt;
  &lt;li&gt;Delivery SLO - It says this updates daily and should be there (where!?) by 08:00 UTC. It also says it‚Äôs late today and has a link to a PagerDuty alert page.&lt;/li&gt;
  &lt;li&gt;Schema - A list of all of the columns and their types, as well as a brief description of each. There‚Äôs an &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;artist_id&lt;/code&gt; (string) column and a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;dominant_genres&lt;/code&gt; column, which is a list of (string, float) pairs. You wonder how long the list is, and really want to to actually read the data to find out.&lt;/li&gt;
  &lt;li&gt;Access - There‚Äôs a disclaimer saying I don‚Äôt have access to read this data. There‚Äôs also a link to request access.&lt;/li&gt;
  &lt;li&gt;Counters - There‚Äôs not much here, but it says there are about 10,000 rows. You expected there to be more.&lt;/li&gt;
  &lt;li&gt;Format - It‚Äôs stored in Avro format and also in Snowflake. Two copies?&lt;/li&gt;
  &lt;li&gt;URI - You were expecting something starting with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;s3://&lt;/code&gt; or &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;gs://&lt;/code&gt; or even &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;hdfs://&lt;/code&gt;, or a Snowflake table name, but it says &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;lyb://artist-meta.DominantGenres&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;So you have a fair amount of information about what‚Äôs in here but still no way to find the data. You ask your teammate and she says ‚ÄúOh, it‚Äôs in Lybrary.‚Äù That must be what &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;lyb&lt;/code&gt; is short for, but you still have no idea what that means. ‚ÄúType this into your terminal: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;lyb ls lyb://artist-metadata.DominantGenres&lt;/code&gt;‚Äù&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ lyb ls artist-metadata.DominantGenres

Access denied. User adam@thecompany.com does not have read access to DataSet artist-metadata.DominantGenres
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;It‚Äôs getting annoying to just see 1 single row of 1 DataSet at this company. You go back to Backstage and request access, which is approved almost immediately.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ lyb ls artist-metadata.DominantGenres

Date        |  Version Count  |  Latest Version  |  Location
=================================================================================================================
2020-09-01  |        1        |     912ec8       |   gs://artist-metadata.DominantGenres_60e0c6/2020/09/02/912ec8
            |                 |                  |   snow://artist-metadata/dominant_genres/912ec8
2020-09-02  |        1        |     42728f       |   gs://artist-metadata.DominantGenres_60e0c6/2020/09/02/42728f
            |                 |                  |   snow://artist-metadata/dominant_genres/42728f
2020-09-03  |        2        |     922d6e       |   gs://artist-metadata.DominantGenres_60e0c6/2020/09/03/922d6e
            |                 |                  |   snow://artist-metadata/dominant_genres/922d6e
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;OK. So what we have here is a system that controls who can read this DataSet. DataSets are identified by some internal &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;lyb://&amp;lt;DataSet&amp;gt;&lt;/code&gt; URI that points you to the actual information. In this case it seems like there are copies of this both in Google Cloud Storage and Snowflake. It also looks like every version of this DataSet is dated and versioned. You suspect that there‚Äôs some access logging going on behind the scenes as well. The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;lyb help&lt;/code&gt; menu is now making much more sense. Finally, we can see some data:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ lyb head -n2 artist-metadata.DominantGenres 2020-09-03 gs
{&quot;artist_id&quot;: &quot;123abc&quot;, &quot;dominant_genres&quot;: [(&quot;rock&quot;, 0.9), (&quot;pop&quot;, 0.04)]}
{&quot;artist_id&quot;: &quot;789xyz&quot;, &quot;dominant_genres&quot;: [(&quot;rap&quot;, 0.3), (&quot;rock&quot;, 0.5), (&quot;funk&quot;, 0.2)]}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;You suspect that second artist might be the band 311 and are mad that &lt;em&gt;‚Äúamber is the color of her energy‚Äù&lt;/em&gt; is now stuck in your head. Despite that, you‚Äôre starting to realize that there is a pretty significant amount of infrastructure around how and where data is stored and read, and there are probably some rules about how data is stored ‚Äúin Lybrary‚Äù in order for this to all work. It‚Äôs a lot to take in for a new hire, but you head home for the day excited, and desperate to get that song out of your head.&lt;/p&gt;

&lt;h2 id=&quot;part-2-let-me-see-some-dataprogramatically&quot;&gt;Part 2: Let me see some data‚Ä¶programatically.&lt;/h2&gt;

&lt;p&gt;You‚Äôre back at your desk and ready to finally clone your team‚Äôs repo and open an IDE. You poke around at some python files in a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;tasks&lt;/code&gt; directory and see 12 or 13 tasks defined. You decide you‚Äôll try writing one to see which genres are associated with the most popular artists. It turns out the ‚ÄúArtist Metadata‚Äù team also makes a whole suite of DataSets containing popularity rankings (globally, by country, by language, etc).&lt;/p&gt;

&lt;p&gt;Naturally, you copy/paste an existing task and modify it to do what you want. It looks like this:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;GenresOfPopularArtists&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SnowflakeTask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
    Seems like these class-level variables are configurable parameters.
    &quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;date&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DateParameter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;top_n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Parameter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;defualt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;requirements&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
        Oh nice, there's a `SnowflakeSource` class that takes a DataSet name and date. It must use Lybrary to find the table name.
        &quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;s&quot;&gt;&quot;dominant-genres&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SnowflakeSource&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
                &lt;span class=&quot;s&quot;&gt;&quot;artist-metadata.DominantGenres&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;date&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
            &lt;span class=&quot;s&quot;&gt;&quot;popular-artists&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SnowflakeSource&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
                &lt;span class=&quot;s&quot;&gt;&quot;artist-metadata.PopularArtistsGlobal&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;date&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;query&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
        Seems like I can just write a query and it formats in the tables and parameters for me.

        You do an inner join between the most popular `top_n` artists and their respective genres,
        then count how many times you see each genre.
        &quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
        SELECT artist_genres.top_genre, count(*) AS genre_count FROM
        (SELECT artist_id, genre_name FROM  WHERE genre_score &amp;gt; .1) artist_genres
        JOIN
        (SELECT artist_id FROM  WHERE global_rank &amp;gt; ) popular_artists
        ON (artist_genres.artist_id = popular_artists.artist_id)
        GROUP BY 1
        &quot;&quot;&quot;&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
        There's a SnowflakeOutput just like a SnowflakeSource.

        You wonder how teams get data into Avro/GCS as well.
        &quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SnowflakeOutput&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data_set&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;artist-analytics.GenresOfPopularArtists&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;date&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;date&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;And of course this task needs to be scheduled to run regularly, which means YAML. It seems pretty simple, but you suspect this is the tip of a very large iceberg.&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;task&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;GenresOfPopularArtists&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;frequency&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;daily&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;params&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;top_n&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1000&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Your teammate reviews your PR and asks if you ran it in test mode first. You did, so the PR gets approved and merged. A few minutes later you check Backstage and there‚Äôs your DataSet! It doesn‚Äôt have much information there yet, and there‚Äôs a big red warning that no SLO has been defined.&lt;/p&gt;

&lt;p&gt;There‚Äôs a new section to the page, though, because it knows you‚Äôre the owner of this DataSet. You click a button that says ‚ÄúBackfill Data‚Äù and 5 minutes later there is a table schema displayed, counters saying there are 125 rows of data (one per genre) - just what you saw in test mode. It even shows that this DataSet depends on &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;artist-metadata.DominantGenres&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;artist-metadata.PopularArtistsGlobal&lt;/code&gt;. To top it off, you‚Äôre in Lybrary!&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ lyb ls artist-metadata.DominantGenres

Date        |  Version Count  |  Latest Version  |  Location
=================================================================================================================
2020-09-03  |        1        |     d2a225       |   snow://artist-analytics/genres_of_popular_artists/d2a225
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;your-new-life-in-the-data-mesh&quot;&gt;Your new life in the Data Mesh&lt;/h2&gt;

&lt;p&gt;So much automation is required to make this work, but you‚Äôve only been here for two days and don‚Äôt really need to understand it all quite yet. You‚Äôve got helpful teammates and a support channel in Slack (with 1,500 members - yikes!). What‚Äôs important is that you have a few tools at your disposal:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;A place to find DataSets and a good amount of information about them.&lt;/li&gt;
  &lt;li&gt;A handy system for keeping track of where data is, and who can read it.&lt;/li&gt;
  &lt;li&gt;A python library for defining workflow tasks and defining inputs/outputs dynamically (via the DataSet name, not the actual location).&lt;/li&gt;
  &lt;li&gt;A pretty impressive CI/CD system.&lt;/li&gt;
  &lt;li&gt;Something that automatically starts running your task once it‚Äôs merged to GitHub.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;There are 1,000 questions to ask about who builds the infrastructure tools, the organizational implications, trust between teams, how to upgrade that python library, etc. They‚Äôre all very important questions with a huge impact on how you decide to run your large enterprise, but I don‚Äôt think answering any of them will help understand what the day-to-day life of an engineer is like. I‚Äôm hoping this post helped shed some light on that.&lt;/p&gt;</content><author><name></name></author><summary type="html">I like the concept of Data Mesh OK, but _love_ the Data Mesh drama on Twitter. üçø&amp;mdash; Adam Laiacano (@adamlaiacano) August 13, 2021</summary></entry><entry><title type="html">Code Interviews</title><link href="http://localhost:4000/interviews/2021/08/10/interviews.html" rel="alternate" type="text/html" title="Code Interviews" /><published>2021-08-10T21:18:32-04:00</published><updated>2021-08-10T21:18:32-04:00</updated><id>http://localhost:4000/interviews/2021/08/10/interviews</id><content type="html" xml:base="http://localhost:4000/interviews/2021/08/10/interviews.html">&lt;p&gt;For most of us, interviewing is hard. And annoying, frustrating, and stressful. Most interviews these days consist of a string of 1-hour interviews covering:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Programming (sometimes 2 of these).&lt;/li&gt;
  &lt;li&gt;Systems design.&lt;/li&gt;
  &lt;li&gt;1-2 specialization-specific interviews: ML, Data Engineering, Frontend, Distributed Systems, etc.&lt;/li&gt;
  &lt;li&gt;An interview with a hiring manager. Sometimes this is about ‚Äúleadership‚Äù or other general topics depending on the role.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The programming interview is probably the most hated. I personally don‚Äôt like being on either side of these interviews. Leetcode-style problems that test &lt;em&gt;CS fundamentals&lt;/em&gt; can be fun puzzles for some people, and are arguably a decent evaluation of junior engineers without industry experience, but it‚Äôs a &lt;a href=&quot;https://twitter.com/PhDemetri/status/1425579904205299721&quot;&gt;common&lt;/a&gt; &lt;a href=&quot;https://twitter.com/CubicleApril/status/1424011476889702402&quot;&gt;complaint&lt;/a&gt; among &lt;a href=&quot;https://twitter.com/andrew_n_carr/status/1341837026191011842&quot;&gt;senior engineers&lt;/a&gt; that they have to study material that they haven‚Äôt used in years to get a job where they won‚Äôt use it. I‚Äôve certainly come out of interviews tempted to ask ‚ÄúIs this the sort of thing your engineers actually do?‚Äù This tweet, from the author of &lt;a href=&quot;https://brew.sh/&quot;&gt;Homebrew&lt;/a&gt;, lives in infamy.&lt;/p&gt;

&lt;blockquote class=&quot;twitter-tweet&quot; data-dnt=&quot;true&quot; data-theme=&quot;dark&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;Google: 90% of our engineers use the software you wrote (Homebrew), but you can‚Äôt invert a binary tree on a whiteboard so fuck off.&lt;/p&gt;&amp;mdash; Max Howell (@mxcl) &lt;a href=&quot;https://twitter.com/mxcl/status/608682016205344768?ref_src=twsrc%5Etfw&quot;&gt;June 10, 2015&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async=&quot;&quot; src=&quot;https://platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;

&lt;p&gt;There are a few questions that people like to use as punching bags. Invert a binary tree. Reverse a linked list. Perform breadth-first and/or depth-first tree traversals. Anything to do with heaps. I recently read the &lt;a href=&quot;https://www.hillelwayne.com/post/linked-lists/&quot;&gt;history of the ‚ÄúReverse A Linked List‚Äù problem&lt;/a&gt; and find this take fascintating. The goal wasn‚Äôt to reverse a linked list, it was to make sure you are familiar with pointer manipulation in C, and reversing the linked list was a good way to demonstrate that.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;In the early 80‚Äôs, C programmers were in high demand. Interviewers used questions that specifically tested your experience with C, which meant problems involving lots of pointer manipulation. This ingrained LL questions as a cultural institution in many places, especially places doing lots of low-level work, like Microsoft and Google. From there, it was exported to the wider software world, and lacking the original context, people assumed it was about ‚Äútesting CS fundamentals‚Äù or ‚Äúquick thinking‚Äù.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The fact remains that it‚Äôs an important part of an interview to make sure that a software engineer can code. So if we‚Äôre going to be asked to reverse a linked list, what is the real underlying assessment? In 2021, that is probably no longer about pointer manipulation. What should it be about, then? Let‚Äôs dig in and have some fun.&lt;/p&gt;

&lt;h2 id=&quot;reversing-a-linked-list&quot;&gt;Reversing a Linked List&lt;/h2&gt;

&lt;p&gt;We‚Äôll start with the classic algorithm question. My solution is &lt;a href=&quot;https://gist.github.com/alaiacano/35a63e7631b60641fc0342f31461b80d#file-ll-py&quot;&gt;here&lt;/a&gt;. Inserting new nodes at the head of the list is &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;O(1)&lt;/code&gt; and reversing the list is &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;O(N)&lt;/code&gt;, and does so by moving pointers around and not making a full copy of the list in memory.&lt;/p&gt;

&lt;p&gt;To populate, print, reverse, and then print the list again, we‚Äôd do this:&lt;/p&gt;

&lt;script src=&quot;https://gist.github.com/35a63e7631b60641fc0342f31461b80d.js?file=run_ll.py&quot; type=&quot;text/javascript&quot;&gt;&lt;/script&gt;

&lt;p&gt;Wonderful. In the real world, we would have used &lt;a href=&quot;https://github.com/python/cpython/blob/e5c8ddb1714fb51ab1defa24352c98e0f01205dc/Objects/listobject.c#L1042-L1056&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;List.reverse&lt;/code&gt;&lt;/a&gt; from the standard library, but this produces the same result. Would we have run the code in a module like this? Probably not!&lt;/p&gt;

&lt;h2 id=&quot;enter-the-linkedlist-pipeline&quot;&gt;Enter the LinkedList Pipeline&lt;/h2&gt;

&lt;p&gt;Let‚Äôs rewrite how we use this &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;LinkedList&lt;/code&gt; class into something a little more &lt;em&gt;modern&lt;/em&gt;:&lt;/p&gt;

&lt;script src=&quot;https://gist.github.com/35a63e7631b60641fc0342f31461b80d.js?file=pipeline1.yaml&quot; type=&quot;text/javascript&quot;&gt;&lt;/script&gt;

&lt;p&gt;YAML! Nice. YAML is fun to joke about, but Vicki Boykis posted &lt;a href=&quot;https://twitter.com/vboykis/status/1407821631997759488&quot;&gt;a twitter poll&lt;/a&gt; about which languages people use in Data Science/ML and the most common reply was ‚Äúdoes YAML count?‚Äù If everyone asks, it means yes.&lt;/p&gt;

&lt;p&gt;The above YAML does not actually do anything, and this is ostensibly a post about software coding interviews, so let‚Äôs build something that reverses a linked list given this pipeline definition. Is this overkill for the goal of reversing a 4-element linked list? Sure. But it‚Äôs a good analog to the modular systems that we are paid to build and use as software engineers, especially Data/ML engineers.&lt;/p&gt;

&lt;p&gt;It is increasingly common to use this kind of ‚Äúpipeline-as-YAML‚Äù configuration to piece together a workflow of pre-built components &lt;sup id=&quot;a1&quot;&gt;&lt;a href=&quot;#f1&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;. Some real examples of this are &lt;a href=&quot;https://www.tensorflow.org/tfx/guide/understanding_tfx_pipelines#component&quot;&gt;TFX components&lt;/a&gt;, &lt;a href=&quot;https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html&quot;&gt;scikit-learn Pipelines&lt;/a&gt;, or &lt;a href=&quot;https://airflow.apache.org/docs/apache-airflow/1.10.12/concepts.html&quot;&gt;Airflow DAGs&lt;/a&gt;. Perhaps &lt;em&gt;components&lt;/em&gt; are the new &lt;em&gt;pointers&lt;/em&gt;. If that‚Äôs the case, let‚Äôs make a coding question that will use this context to assess coding ability.&lt;/p&gt;

&lt;h3 id=&quot;coding-problem-implement-a-framework-to-execute-this-pipeline&quot;&gt;Coding problem: Implement a framework to execute this pipeline&lt;/h3&gt;

&lt;p&gt;First we‚Äôll need to define a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Task&lt;/code&gt; class to carry out the logic of each &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;task&lt;/code&gt; defined in the YAML. A &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Task&lt;/code&gt; may take an input &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;LinkedList&lt;/code&gt; from a previous &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Task&lt;/code&gt;, performs some operation on it, and produces an output. Here‚Äôs the interface:&lt;/p&gt;

&lt;script src=&quot;https://gist.github.com/35a63e7631b60641fc0342f31461b80d.js?file=base_task.py&quot; type=&quot;text/javascript&quot;&gt;&lt;/script&gt;

&lt;p&gt;It takes an input &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;LinkedList&lt;/code&gt; and a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;name&lt;/code&gt; for the task, and has an abstract &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;execute&lt;/code&gt; method that will have to mutate &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;self._lst&lt;/code&gt;. As an interviewer, I‚Äôd ask whether mutating &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;self._lst&lt;/code&gt; is ideal here. ‚ÄúPipelines‚Äù are a pretty functional concept, where side effects are not ideal. How would the candidate account for this mutation and make sure it‚Äôs safe? This is a great opportunity for a conversation about ways of building software, which you don‚Äôt really get when the problem is to implement a single algorithm.&lt;/p&gt;

&lt;p&gt;With that, let‚Äôs extend &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Task&lt;/code&gt; to perform the actions seen in the YAML: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;push_values&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;reverse_list&lt;/code&gt;, and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;print_list&lt;/code&gt;.&lt;/p&gt;

&lt;script src=&quot;https://gist.github.com/35a63e7631b60641fc0342f31461b80d.js?file=tasks.py&quot; type=&quot;text/javascript&quot;&gt;&lt;/script&gt;

&lt;p&gt;You can see that I moved the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;reverse&lt;/code&gt; method into &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ReverseListTask&lt;/code&gt;, so we can remove the method from the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;LinkedList&lt;/code&gt; class. One benefit of this task-based approach is that the logic that we want to perform is located within the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Task&lt;/code&gt;, and this helps us achieve that task. None of the other &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Task&lt;/code&gt;s need to know about reversing a list, and having code around to do unnecessary tasks might become step towards ‚ÄúDependency Hell.‚Äù&lt;/p&gt;

&lt;p&gt;Our YAML config has an &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;action&lt;/code&gt; field that we can use to decide which of these subclasses to use for each step in the pipeline. Let‚Äôs use a factory function for that &lt;sup id=&quot;a2&quot;&gt;&lt;a href=&quot;#f2&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;

&lt;script src=&quot;https://gist.github.com/35a63e7631b60641fc0342f31461b80d.js?file=task_factory.py&quot; type=&quot;text/javascript&quot;&gt;&lt;/script&gt;

&lt;p&gt;Now it‚Äôs time to think about parsing the YAML config itself. We‚Äôll put each &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;task&lt;/code&gt; in the YAML array into a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;TaskDefinition&lt;/code&gt; dataclass to hold all of the parameters and values:&lt;/p&gt;

&lt;script src=&quot;https://gist.github.com/35a63e7631b60641fc0342f31461b80d.js?file=task_definition.py&quot; type=&quot;text/javascript&quot;&gt;&lt;/script&gt;

&lt;p&gt;At this point, we have:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Broken each step of the pipeline into a ‚Äútask,‚Äù which is described by a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;TaskDefinition&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;Made an abstract &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Task&lt;/code&gt; class that can be extended to perform the actual work defined by each stage of the pipeline.&lt;/li&gt;
  &lt;li&gt;Made a helper function to convert an &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;action&lt;/code&gt; (string) from the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;TaskDefinition&lt;/code&gt; into the appropriate &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Task&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Now we can write a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Parser&lt;/code&gt; class to read the whole YAML file and turn it into a list of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;TaskDefinitions&lt;/code&gt; that we‚Äôll need to run. It will have three methods:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;parse&lt;/code&gt; to read the YAML and produce a list of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;TaskDefinition&lt;/code&gt;s&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;describe&lt;/code&gt; to print a preview of which tasks will be executed&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;run&lt;/code&gt; to create each &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Task&lt;/code&gt; in the pipeline and call &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;execute&lt;/code&gt; on it&lt;/li&gt;
&lt;/ul&gt;

&lt;script src=&quot;https://gist.github.com/35a63e7631b60641fc0342f31461b80d.js?file=parser.py&quot; type=&quot;text/javascript&quot;&gt;&lt;/script&gt;

&lt;p&gt;Now when we execute &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;parser.py&lt;/code&gt; we‚Äôll do this:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;__name__&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;__main__&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Parser&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;pipeline.yaml&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parse&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;describe&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;And we get the expected output:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ python pipeline.py

~~ Tasks that will execute ~~
push_values - populate the list - {'elements': [1, 2, 3, 4]}
print_list - print the list - {}
reverse_list - reverse the list - {}
print_list - print the reversed list - {}
INFO:root:~~~
INFO:root:Populating the list with: [1, 2, 3, 4]
INFO:root:~~~
the list is
4, 3, 2, 1
INFO:root:~~~
INFO:root:Reversing the list
INFO:root:~~~
the list is
1, 2, 3, 4
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;We did it! We reversed a linked list. Want to add &lt;a href=&quot;https://www.geeksforgeeks.org/top-20-linked-list-interview-question/&quot;&gt;some other task for a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;LinkedList&lt;/code&gt;&lt;/a&gt;? No problem, we just have to:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Define a new &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;action&lt;/code&gt; for the YAML config.&lt;/li&gt;
  &lt;li&gt;Extend &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Task&lt;/code&gt; with a new subclass and implement &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;execute&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;Write some unit &amp;amp; integration tests, which are glaringly absent from this post!&lt;/li&gt;
  &lt;li&gt;Add a line to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;task_factory&lt;/code&gt; to produce the new class for the appropriate value of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;action&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;Document it and communicate it to the users of your platform.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;the-twist&quot;&gt;The twist&lt;/h2&gt;

&lt;p&gt;Most coding interviews have a secret second part. If a candidate solves the problem with lots of time to spare, we can ask an add-on question. Is this fair? Probably not. If a candidate can pass the interview by solving just the first part, they shouldn‚Äôt be able to fail it by attempting the second. Hopefully by solving the second part of the question they considered for a higher title, and not penalized for getting stuck on it.&lt;/p&gt;

&lt;p&gt;In this case, we could make a more complex task execution graph. The execution graph looks like this in v1.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;push_values -&amp;gt; print_list -&amp;gt; reverse_list -&amp;gt; print_list
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The first &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;print_list&lt;/code&gt; task and the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;reverse_list&lt;/code&gt; tasks are really operating on the same input (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;print_list&lt;/code&gt; is really just a side effect). We could allow each task to specify its parent and re-draw the graph to look like this.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;               / -&amp;gt; print_values
              /
push_values -
              \
               \ -&amp;gt; reverse_list -&amp;gt; print_values
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;So we can change the YAML config format a bit to include an &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;id&lt;/code&gt; for each task and a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;parent&lt;/code&gt; indicating the ID of upstream task. The new config will look like this. It‚Äôs a breaking change, so we‚Äôve moved to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;apiVersion: 2&lt;/code&gt;.&lt;/p&gt;

&lt;script src=&quot;https://gist.github.com/35a63e7631b60641fc0342f31461b80d.js?file=pipeline2.yaml&quot; type=&quot;text/javascript&quot;&gt;&lt;/script&gt;

&lt;p&gt;Now we can implement a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Parser2&lt;/code&gt; that‚Äôs a little more advanced. Rather than a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;List[Task]&lt;/code&gt; we‚Äôll create a dictionary from &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;task_id -&amp;gt; List[downstream Tasks]&lt;/code&gt;, and step through all of the tasks. Here‚Äôs how &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;run&lt;/code&gt; is implemented now (see the link at the bottom for the full code):&lt;/p&gt;

&lt;script src=&quot;https://gist.github.com/35a63e7631b60641fc0342f31461b80d.js?file=parser2.py&quot; type=&quot;text/javascript&quot;&gt;&lt;/script&gt;

&lt;p&gt;I made a &lt;em&gt;graph&lt;/em&gt; of parent and child tasks, and then step through starting at the head and hitting every child, passing the output of the parent to each of its children tasks. &lt;strong&gt;It‚Äôs a depth-first graph traversal&lt;/strong&gt; just hiding there right in front of us!&lt;/p&gt;

&lt;h2 id=&quot;wrap-up&quot;&gt;Wrap-up&lt;/h2&gt;

&lt;blockquote class=&quot;twitter-tweet&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;All job interview processes are flawed. They&amp;#39;re just flawed in different ways, and some of those flaws work to your advantage and some don&amp;#39;t. That&amp;#39;s it, that&amp;#39;s the newsletter.&lt;/p&gt;&amp;mdash; Vicki Boykis (@vboykis) &lt;a href=&quot;https://twitter.com/vboykis/status/1316019970032070661?ref_src=twsrc%5Etfw&quot;&gt;October 13, 2020&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async=&quot;&quot; src=&quot;https://platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;

&lt;p&gt;The original quote that I shared suggested that asking a candidate to implement a specfic algorithm (reverse a linked list) was a vehicle for testing a broader set of knowledge (experience with writing in C). In my problem, we ask directly about the broader set of knowledge (familiarity with pipelines / DAGs), and reveal a situation where a specific algorithm needs to be used (graph traversal).&lt;/p&gt;

&lt;p&gt;My task is far more life-like, putting the candidate in a familiar situation and likely less stressful state of mind. If the candidate asks if this is what your engineers really do, you can more confidently say ‚Äúyes.‚Äù There is also much more opportunity to discuss design approaches and trade-offs, and a chance at the end to speculate how it could be advanced further (Async tasks? Just use Airflow?).&lt;/p&gt;

&lt;p&gt;I‚Äôll ask that you consider putting a little more effort into your programming questions than picking something straight from leetcode. It will be more enjoyable for both the interviewer and candidate, provide a better hiring signal, and allow you to base your hiring decision more on skill and experience than the candidate‚Äôs luck.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;b id=&quot;f1&quot;&gt;1&lt;/b&gt; This idea is up for debate. Should programmers &lt;a href=&quot;https://cacm.acm.org/magazines/2008/8/5355-interview-donald-knuth-a-lifes-work-interrupted/fulltext&quot;&gt;build from scratch&lt;/a&gt;, or stitch various services/components together (&lt;a href=&quot;https://rachelbythebay.com/w/2020/08/14/jobs/&quot;&gt;‚ÄúVendorOps‚Äù&lt;/a&gt;)? I agree there‚Äôs &lt;a href=&quot;https://twitter.com/drunkcod/status/1429422275535769606?s=21&quot;&gt;room for both&lt;/a&gt;. I hope it‚Äôs obvious that in this post I am focusing on the latter. &lt;a href=&quot;#a1&quot;&gt;‚Ü©&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;b id=&quot;f2&quot;&gt;2&lt;/b&gt; A factory! In Python!? They‚Äôre out there, folks. &lt;a href=&quot;#a2&quot;&gt;‚Ü©&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Thanks to &lt;a href=&quot;https://twitter.com/mattnworb&quot;&gt;Matt Brown&lt;/a&gt; for feedback on this post.&lt;/p&gt;</content><author><name></name></author><category term="interviews" /><summary type="html">For most of us, interviewing is hard. And annoying, frustrating, and stressful. Most interviews these days consist of a string of 1-hour interviews covering:</summary></entry><entry><title type="html">Developing Data Pipelines</title><link href="http://localhost:4000/data-engineering/2020/11/27/data-eng-tips.html" rel="alternate" type="text/html" title="Developing Data Pipelines" /><published>2020-11-27T20:18:32-05:00</published><updated>2020-11-27T20:18:32-05:00</updated><id>http://localhost:4000/data-engineering/2020/11/27/data-eng-tips</id><content type="html" xml:base="http://localhost:4000/data-engineering/2020/11/27/data-eng-tips.html">&lt;p&gt;Someone at work recently asked for some tips on developing data pipelines. They were coming with plenty of experience in data manipulation in Python (filtering, grouping, aggregating, etc) and were used to the fast iteration that you get with in-memory Pandas dataframes. It‚Äôs a bit of a transition to a world of distributed calculations where it is much slower to experiment with such data manipulations - but in return for this patience we can scale to processing terabytes of data at a time.&lt;/p&gt;

&lt;p&gt;At Spotify, we use &lt;a href=&quot;https://www.github.com/spotify/scio&quot;&gt;Scio&lt;/a&gt; for this sort of processing and have thousands of jobs running every day&lt;sup id=&quot;fnref:1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;. (Py)Spark, Scalding, or some other Map/Reduce style framework. I wrote a few tips that I thought might be worth sharing. Some of these are scio-specific, but most of the ideas should generalize&lt;sup id=&quot;fnref:2&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;

&lt;p&gt;In this environment, executing your code (‚Äúsubmitting a job‚Äù) takes time, processing lots of data takes time (and money), inspecting results requires hunting down storage locations in some cloud storage bucket, errors are opaque and might take a long time to materialize. I put together a few tips for someone transitioning from a ‚Äúquick iteration‚Äù development process to a ‚Äúwait this takes &lt;em&gt;how long&lt;/em&gt; to run?‚Äù development process.&lt;/p&gt;

&lt;h3 id=&quot;lean-on-types&quot;&gt;Lean on types&lt;/h3&gt;

&lt;p&gt;Scala‚Äôs type system &amp;amp; compiler are extremely helpful when writing this kind of code. You know that things will &lt;em&gt;probably&lt;/em&gt; run reasonably well if it compiles. Python is perfectly happy sending strings to functions that expect integers, even if you have type hints. Scala will break on that and the IDE (intellij is king) helps a lot. That doesn‚Äôt mean there aren‚Äôt logical errors or the elusive &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;RuntimeException&lt;/code&gt; in there!&lt;/p&gt;

&lt;p&gt;You‚Äôre going to end up chaining a lot of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;map&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;filter&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;groupBy&lt;/code&gt; and other operations together. For example, say you have a data set with all of the city populations in the world and want to get all of the state populations within the US. This requires a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;filter&lt;/code&gt; to keep only cities in the US, then a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;map&lt;/code&gt; to extract the state (province) name and population from the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;City&lt;/code&gt; object, then a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sumByKey&lt;/code&gt; to sum all of the cities in that state.&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;City&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;country&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;province&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;city&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;population&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;// sc.parallelize puts a manually-defined List into an SCollection&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;cities&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;SCollection&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;City&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;sc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;parallelize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;List&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;
  &lt;span class=&quot;nc&quot;&gt;City&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;US&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Massachusetts&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Boston&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;694583&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;),&lt;/span&gt;
  &lt;span class=&quot;nc&quot;&gt;City&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;US&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;New York&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;New York&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;8399000&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;),&lt;/span&gt;
  &lt;span class=&quot;nc&quot;&gt;City&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;FR&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Ile de France&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Paris&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2161000&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;c1&quot;&gt;// ...and all of the rest of the cities&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;statePopulations&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;SCollection&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;, &lt;span class=&quot;kt&quot;&gt;Int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cities&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;filter&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;row&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;row&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;country&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;US&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;          &lt;span class=&quot;c1&quot;&gt;// SCollection[City]&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;map&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;row&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;row&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;province&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;row&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;population&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;// SCollection[(String, Int)]&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;sumByKey&lt;/span&gt;                                       &lt;span class=&quot;c1&quot;&gt;// SCollection[(String, Int)]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;IDEs like &lt;a href=&quot;https://www.jetbrains.com/idea/&quot;&gt;IntelliJ&lt;/a&gt; or &lt;a href=&quot;https://code.visualstudio.com/&quot;&gt;Visual Studio Code&lt;/a&gt; (with the Scala Metals plugin) will tell you what type of data is inside of your &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SCollection&lt;/code&gt; at each step in the chain, as I‚Äôve done in the comments above. The IDE will tell you that &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;statePopulations&lt;/code&gt; is in fact a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SCollection[(String, Int)]&lt;/code&gt; and will tell you if it‚Äôs a type mismatch.&lt;/p&gt;

&lt;p&gt;Some people like to define the variable first:&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;statePopulations&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;SCollection&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;, &lt;span class=&quot;kt&quot;&gt;Int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cities&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;And others like to leave the type definition empty and ask the IDE to fill it in once all the code is written. It‚Äôs helpful either way.&lt;/p&gt;

&lt;h3 id=&quot;tests-and-debugger&quot;&gt;Tests and debugger&lt;/h3&gt;

&lt;p&gt;You don‚Äôt have to write formal tests &lt;em&gt;first&lt;/em&gt;, but they certainly can be helpful if you‚Äôre stuck figuring something out. Scio has a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;JobTest&lt;/code&gt; class for tests and other frameworks have equivalents for:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Specifying input data&lt;/li&gt;
  &lt;li&gt;Passing any &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;arg&lt;/code&gt;s to the job (this is typically how you specify input/output paths)&lt;/li&gt;
  &lt;li&gt;Checking that the output matches expectations&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;A simple example of a &lt;a href=&quot;https://github.com/spotify/scio/blob/master/scio-examples/src/main/scala/com/spotify/scio/examples/WordCount.scala&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;WordCount&lt;/code&gt; job&lt;/a&gt; would look like this:&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;package&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;com.spotify.scio.examples&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;com.spotify.scio.io._&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;com.spotify.scio.testing._&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;WordCountTest&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;extends&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;PipelineSpec&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;inData&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Seq&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Seq&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;a b c d e&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;a b a b&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;expected&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Seq&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Seq&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;a: 3&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;b: 3&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;c: 1&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;d: 1&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;e: 1&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;

  &lt;span class=&quot;s&quot;&gt;&quot;WordCount&quot;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;should&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;count correctly&quot;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;nc&quot;&gt;JobTest&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;com.spotify.scio.examples.WordCount.&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;--input=in.txt&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;--output=out.txt&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;input&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;TextIO&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;in.txt&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inData&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;TextIO&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;out.txt&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;coll&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;coll&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;should&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;containInAnyOrder&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;expected&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;You can run the test using an IDE debugger and place breakpoints in the Scio job to make sure the values are what you expect at various points in the pipeline. &lt;strong&gt;This is probably going to be most similar to the iterative experience in a Jupyter notebook.&lt;/strong&gt; Setting up all of the mocked test data can be annoying (especially if your input data is a complex format with lots of embedded records). For good, reliable code you‚Äôll write these tests eventually anyway!&lt;/p&gt;

&lt;h3 id=&quot;use-a-lot-of-counters&quot;&gt;Use a lot of counters.&lt;/h3&gt;

&lt;p&gt;There are different types of &lt;a href=&quot;https://spotify.github.io/scio/examples/MetricsExample.scala.html&quot;&gt;counters&lt;/a&gt; that you can increment on certain conditions to make sure you do/don‚Äôt see what you are looking for. Some of the counters that Scio provides are:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Incremental counter to be incremented inside the pipeline (the most common use case that I‚Äôve seen)&lt;/li&gt;
  &lt;li&gt;Distribution to track min, max, count, sum, mean&lt;/li&gt;
  &lt;li&gt;Gauge to track the latest value of a certain metric (this is more useful in a streaming context than batch processing)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For long-term monitoring of data quality, these counters (Hadoop and Spark have similar concepts) can be recorded and monitored. At Spotify, we have a service that can send PagerDuty alerts if certain counter thresholds are not met or are exceeded.&lt;/p&gt;

&lt;h3 id=&quot;use-the-computation-graph-ui&quot;&gt;Use the computation graph UI&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/assets/monitoring-side-input-read.png&quot; alt=&quot;Datflow graph example&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The image above is a Dataflow computation graph from the &lt;a href=&quot;https://cloud.google.com/dataflow/docs/guides/using-monitoring-intf&quot;&gt;Cloud Dataflow docs&lt;/a&gt; that we see whenever we run a Scio job. You can click on any node in the Dataflow graph when it is running and see the number of input and output elements. For example, if you‚Äôre doing an inner join of two &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SCollection&lt;/code&gt;s and you see &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;X&lt;/code&gt; input records from one &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SCollection&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Y&lt;/code&gt; input records from the other, you should see &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;X (union on key) Y&lt;/code&gt; output records.&lt;/p&gt;

&lt;p&gt;As the developer, you probably have some intuition of what that number should be, and can confirm it in the job execution UI. If you don‚Äôt see what you expect, something could be wrong in the join. This also applies to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;filter&lt;/code&gt; or &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;flatMap&lt;/code&gt; functions, and many more.&lt;/p&gt;

&lt;p&gt;In Scio, you can also use &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.withName(&quot;a description of this step&quot;)&lt;/code&gt; on any SCollection. So for example:&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;sc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;parallelize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;List&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;e&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;withName&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;remove odd values&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;the&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;next&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;thing&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;...)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;filter&lt;/code&gt; node in the Dataflow graph will show your supplied name, and you‚Äôd expect that the number of output elements should be about half as much as the input.&lt;/p&gt;

&lt;h3 id=&quot;output-previews-to-bigquery&quot;&gt;Output previews to Bigquery&lt;/h3&gt;

&lt;p&gt;I always save a copy of my result to BQ (or Redshift, or Snowflake, or whatever) when developing pipelines, even if it eventually stores its output in a different format. It lets you visually inspect the results and do all of the tricks you‚Äôre used to doing via SQL. You can use &lt;a href=&quot;https://spotify.github.io/scio/io/Type-Safe-BigQuery.html#bigquerytype-totable&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;@BigQueryType.toTable&lt;/code&gt;&lt;/a&gt; to annotate any scala case class and then &lt;a href=&quot;https://spotify.github.io/scio/io/Type-Safe-BigQuery.html#type-safe-bigquery-with-scio&quot;&gt;save it as a BQ table&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Just be careful not to store decrypted PII in your debugging!&lt;/p&gt;

&lt;h3 id=&quot;run-on-a-subset-of-data&quot;&gt;Run on a subset of data&lt;/h3&gt;

&lt;p&gt;If you can limit the amount of data being read or processed (either by filtering/sampling within the job, or processing one day‚Äôs worth of data instead of multiple, etc) that will speed up the iteration process.&lt;/p&gt;

&lt;p&gt;Hopefully some of these ideas will be useful for anyone transitioning from working with libraries like pandas or dplyr to a larger, slower, distributed computation environment.&lt;/p&gt;

&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Scio is a Scala DSL for Apache Beam, which we run on Google Cloud Dataflow. This means we write our logic as Scala functions and it gets executed on a cluster of machines, which Google provides as a managed service.¬†&lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:2&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;TLDR for people familiar with at least one of these: Scio/&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SCollection&lt;/code&gt; == Spark/&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;RDD&lt;/code&gt; == Scalding/&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;TypedPipe&lt;/code&gt;.¬†&lt;a href=&quot;#fnref:2&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name></name></author><category term="data-engineering" /><summary type="html">Someone at work recently asked for some tips on developing data pipelines. They were coming with plenty of experience in data manipulation in Python (filtering, grouping, aggregating, etc) and were used to the fast iteration that you get with in-memory Pandas dataframes. It‚Äôs a bit of a transition to a world of distributed calculations where it is much slower to experiment with such data manipulations - but in return for this patience we can scale to processing terabytes of data at a time.</summary></entry></feed>