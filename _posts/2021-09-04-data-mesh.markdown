---
layout: post
title: "My Life in the Data Mesh"
date: 2021-09-05 00:00:00 -0500
# categories:
---

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">I like the concept of Data Mesh OK, but _love_ the Data Mesh drama on Twitter. üçø</p>&mdash; Adam Laiacano (@adamlaiacano) <a href="https://twitter.com/adamlaiacano/status/1426254483764416514?ref_src=twsrc%5Etfw">August 13, 2021</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

`DATA MESH` has been a [very](https://twitter.com/jcristharif/status/1426320304591327234) popular [punching bag](https://twitter.com/bernhardsson/status/1400461693197570051) on Twitter lately. The volume of jokes has been matched by a [burst](https://cnr.sh/essays/what-the-heck-data-mesh) of [blog posts](https://martinfowler.com/articles/data-mesh-principles.html) [earnestly explaining](https://datameshlearning.substack.com/p/okay-but-just-wtf-is-a-data-mesh) [what a Data Mesh is](https://towardsdatascience.com/what-is-a-data-mesh-and-how-not-to-mesh-it-up-210710bb41e0) followed by more tweets from people saying they still don't understand. When I first heard the term and read about it, I recognized it as the framework that I've been working in for the last 5 years.

## An appreciation for scale

Before joining Spotify in 2016, I was working on Machine Learning at Stripe, where we used [Timberlake](https://github.com/stripe-archive/timberlake) to monitor the progress of map/reduce jobs on the Hadoop cluster. There was one Hadoop cluster which was used for all data processing tasks at the time - mostly by the data team, which included the ML group. When I arrived at Spotify I suggested we use it as well since it was so handy at Stripe. Someone from the data infrastructure group quoted this clip from the Timberlake's README:

> [Stripe's] cluster has 10-40 jobs running simultaneously and about 2,000 jobs running per day. Timberlake's performance has not been tested outside these bounds.

I was told it wouldn't work because Spotify, in 2016, was often running 2,000 Hadoop jobs _concurrently_. Ignore the number of gigabytes being processed, this is a full two orders of magnitude difference in the number of _jobs_ being run. And it wasn't just one "data team" who was using the Hadoop cluster - it seemed like there were 100 different teams each with a couple of data engineers, all submitting [Scalding](github.com/twitter/scalding) or [Crunch](https://crunch.apache.org/) jobs to prepare data for whatever product they were working on. If you find it difficult to imagine having 100x more data pipelines running at your company, mostly by people you've never met, it might also be difficult to appreciate the value of a Data Mesh.

Fast forward five years to 2021. Spotify has [migrated to Google Cloud](https://cloud.google.com/customers/featured/spotify) and our data processing has moved from Hadoop to [Scio](https://engineering.atspotify.com/2019/05/30/scio-0-7-a-deep-dive/) (our Scala DSL for Apache Beam). The number of teams doing data engineering has grown, and keeping track of all of the data that the teams make is hard.
